from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import time
import pandas as pd
import os
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import re

def extract_review_text(raw_html):
    """
    HTMLì—ì„œ ë¦¬ë·° ë³¸ë¬¸ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ì´ë¯¸ì§€ íƒœê·¸ ì œê±° í¬í•¨)
    """
    # âœ… <span> íƒœê·¸ ì¤‘ <img>ë¥¼ í¬í•¨í•œ íƒœê·¸ ì œê±°
    raw_html = re.sub(r'<span[^>]*><img.*?></span>', '', raw_html, flags=re.DOTALL)

    # âœ… <span> íƒœê·¸ ì•ˆì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    review_texts = re.findall(r'<span[^>]*>(.*?)</span>', raw_html, re.DOTALL)

    # âœ… ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
    exclude_keywords = ["í‰ì ", "ì‹ ê³ ", "ì´ë¯¸ì§€ í¼ì³ë³´ê¸°", "ë”ë³´ê¸°", "ë¦¬ë·° ë”ë³´ê¸°/ì ‘ê¸°", "ì‚¬ì§„/ë¹„ë””ì˜¤ ìˆ˜", "ìŠ¤í† ì–´PICK", "í•œë‹¬ì‚¬ìš©"]

    clean_texts = []
    for text in review_texts:
        text = text.strip()
        if not any(keyword in text for keyword in exclude_keywords):
            clean_texts.append(text)

    # âœ… ì •ì œëœ í…ìŠ¤íŠ¸ ë°˜í™˜ (ì—¬ëŸ¬ ì¤„ì„ í•˜ë‚˜ë¡œ í•©ì¹¨)
    return " ".join(clean_texts)

app = Flask(__name__)
CORS(app)  # CORS í—ˆìš©

# í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
options = webdriver.ChromeOptions()
options.add_argument("--start-maximized")  # ë¸Œë¼ìš°ì € ìµœëŒ€í™”
driver = None  # ì „ì—­ ë³€ìˆ˜

@app.route('/start', methods=['GET'])
def start_browser():
    """ ë¸Œë¼ìš°ì € ì‹¤í–‰ (ë¡œê·¸ì¸ìš©) """
    global driver
    if driver is None:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)

    driver.get("https://www.jobplanet.co.kr/users/sign_in")
    return jsonify({"message": "ë¸Œë¼ìš°ì € ì‹¤í–‰ ì™„ë£Œ. ë¡œê·¸ì¸ í›„ 'í¬ë¡¤ë§ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."})

@app.route('/crawl', methods=['POST'])
def crawl():
    """ ë¡œê·¸ì¸ í›„ í¬ë¡¤ë§ ì‹œì‘ """
    global driver
    if driver is None:
        return jsonify({"message": "ë¨¼ì € ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."})

    data = request.json
    target_url = data.get("target_url")

    if not target_url:
        return jsonify({"message": "í¬ë¡¤ë§í•  URLì´ í•„ìš”í•©ë‹ˆë‹¤."})

    parsed_data = []
    page = 1

    while True:
        url = f"{target_url}?page={page}"
        driver.get(url)
        time.sleep(2)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        content_divs = soup.find_all('div', class_='content_body_ty1')

        if len(content_divs) < 1:
            break

        new_data = parse_content(content_divs)
        parsed_data.extend(new_data)
        print(f"Page {page} parsed and added to data.")
        page += 1

    # ì—‘ì…€ë¡œ ì €ì¥
    output_file = "interviews.xlsx"
    columns = ["ë²ˆí˜¸", "ì¸í„°ë·° ë‚´ìš©", "ë©´ì ‘ ì§ˆë¬¸", "ë©´ì ‘ ë‹µë³€", "ì±„ìš© ë°©ì‹", "ë°œí‘œ ì‹œê¸°"]  # 6ê°œë¡œ ìˆ˜ì •

    output_df = pd.DataFrame(parsed_data, columns=columns)
    output_df.to_excel(output_file, index=False)
    print(f"Data saved to {output_file}")

    # âœ… íŒŒì¼ ë‹¤ìš´ë¡œë“œ URLì„ í´ë¼ì´ì–¸íŠ¸ì— ë°˜í™˜
    return jsonify({"message": "í¬ë¡¤ë§ ì™„ë£Œ", "download_url": f"http://localhost:5000/download/{output_file}"})

@app.route('/download/<filename>', methods=['GET'])
def download_file(filename):
    """ í´ë¼ì´ì–¸íŠ¸ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ì œê³µ """
    file_path = os.path.join(os.getcwd(), filename)
    if os.path.exists(file_path):
        return send_file(file_path, as_attachment=True)
    else:
        return jsonify({"message": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

def parse_content(divs):
    """ BeautifulSoupìœ¼ë¡œ í˜ì´ì§€ ë‚´ìš© íŒŒì‹± """
    parsed_data = []
    for idx, div in enumerate(divs, start=1):
        try:
            interview_text = div.find('div', class_='us_label_wrap').find('h2', class_='us_label').get_text(strip=True)
        except:
            interview_text = ''

        try:
            tc_list = div.find('dl', class_='tc_list')
            dd_tags = tc_list.find_all('dd', class_='df1')
            interview_question = dd_tags[0].get_text(separator=" ", strip=True) if len(dd_tags) > 0 else ''
            interview_answer = dd_tags[1].get_text(separator=" ", strip=True) if len(dd_tags) > 1 else ''
            recruitment_method = dd_tags[2].get_text(separator=" ", strip=True) if len(dd_tags) > 2 else ''
            announcement_timing = dd_tags[3].get_text(separator=" ", strip=True) if len(dd_tags) > 3 else ''
        except:
            interview_question = interview_answer = recruitment_method = announcement_timing = ''

        parsed_data.append([idx, interview_text, interview_question, interview_answer,
                            recruitment_method, announcement_timing])
    return parsed_data
@app.route('/start-naver', methods=['GET'])
def start_naver_browser():
    """ ë„¤ì´ë²„ ì‡¼í•‘ëª° ë¸Œë¼ìš°ì € ì‹¤í–‰ """
    global driver
    if driver is None:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)

    driver.get("https://shopping.naver.com/home")  # ë„¤ì´ë²„ ì‡¼í•‘ í™ˆìœ¼ë¡œ ì´ë™
    return jsonify({"message": "ë¸Œë¼ìš°ì €ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì›í•˜ëŠ” ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™ í›„ 'í¬ë¡¤ë§ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."})

@app.route('/naver-crawl', methods=['POST'])
def naver_crawl():
    """ ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘ """
    global driver
    if driver is None:
        return jsonify({"message": "ë¨¼ì € ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."})

    data = request.json
    max_pages = int(data.get("max_pages", 10))  # ê¸°ë³¸ê°’ 10í˜ì´ì§€

    parsed_data = []
    current_page = 1  

    while current_page <= max_pages:
        print(f"ğŸ” {current_page} í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...")

        try:
            review_elements = WebDriverWait(driver, 10).until(
                EC.presence_of_all_elements_located((By.XPATH, "//li[contains(@class, 'BnwL_cs1av')]"))
            )
        except:
            print("ğŸš« ë¦¬ë·° ë¡œë”© ì‹¤íŒ¨")
            break

        for review in review_elements:
            try:
                username = review.find_element(By.XPATH, ".//strong[contains(@class, '_2L3vDiadT9')]").text
                date = review.find_element(By.XPATH, ".//span[contains(@class, '_2L3vDiadT9')]").text
                rating = review.find_element(By.XPATH, ".//em[contains(@class, '_15NU42F3kT')]").text
                
                raw_html = review.get_attribute('innerHTML')
                review_content = extract_review_text(raw_html)

                parsed_data.append([username, date, rating, review_content])
                print(f"âœ… {username} | {date} | í‰ì : {rating}\n{review_content}\n\n" + "-" * 60)
            except Exception as e:
                print(f"âŒ ë¦¬ë·° ì¶”ì¶œ ì˜¤ë¥˜: {e}")

        # âœ… í˜ì´ì§€ë„¤ì´ì…˜ ë¡œì§
        if current_page % 10 != 0:
            try:
                next_page_button = driver.find_element(By.XPATH, f"//a[text()='{current_page + 1}']")
                driver.execute_script("arguments[0].click();", next_page_button)
                time.sleep(3)
                current_page += 1
                continue
            except:
                print(f"ğŸš« {current_page+1} í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ.")
                break
        else:
            try:
                next_button = driver.find_element(By.XPATH, "//a[contains(text(), 'ë‹¤ìŒ')]")
                driver.execute_script("arguments[0].click();", next_button)
                time.sleep(3)
                current_page += 1
            except:
                print("ğŸš« 'ë‹¤ìŒ' ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. í¬ë¡¤ë§ ì¢…ë£Œ.")
                break

    # âœ… ì—‘ì…€ íŒŒì¼ ì €ì¥
    output_file = "naver_reviews.xlsx"
    columns = ["ì‘ì„±ì", "ë‚ ì§œ", "í‰ì ", "ë¦¬ë·°"]
    output_df = pd.DataFrame(parsed_data, columns=columns)
    output_df.to_excel(output_file, index=False)
    print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ë°ì´í„° ì €ì¥ë¨: `{output_file}`")

    return jsonify({"message": "í¬ë¡¤ë§ ì™„ë£Œ", "download_url": f"http://localhost:5000/download/{output_file}"})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
